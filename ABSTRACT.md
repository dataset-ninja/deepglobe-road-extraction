There have been several datasets proposed in the literature for benchmarking algorithms for semantic segmentation of overhead imagery. Some of these can be enumerated as the TorontoCity[54] dataset, the ISPRS 2D semantic labeling dataset [3], the Mnih dataset [39], the SpaceNet dataset [2] and the ISPRS Benchmark for Multi-Platform Photogrammetry [4]. The satellite imagery used in DeepGlobe for the road extraction challenge is sampled from the DigitalGlobe +Vivid Images dataset [1]. It covers images captured over Thailand, Indonesia, and India. The ground resolution of the image pixels is 50 cm/pixel. The images consist of 3 channels (Red, Green and Blue). Each of the original geotiff images are 190584 Ã— 190584 pixels. The annotation process starts by tiling and loading these images in QGIS[7]. Based on this tiling, authors determine useful areas to sample from those countries. For designating useful areas, authors sample data uniformly between rural and urban areas. After sampling authors select the corresponding DigitalGlobe tiff images belonging to those areas. These images are then cropped to extract useful subregions and relevant subregions are sampled by GIS experts. (A useful subregion denotes a part of the image where authors have a good relative ratio between positive and negative examples.) Also, while selecting these subregions, authors try to sample interesting areas uniformly, e.g., those with different types of road surfaces (unpaved, paved, dirt roads), rural and urban areas, etc. An example of one image crop is illustrated in the left panel of Figure 1. It is important to note that the labels generated are pixel-based, where all pixels belonging to the road are labeled, instead of labeling only the centerline.
The final road dataset consists of a total of 8 0570 images and spans a total land area of 2 0220km2. Of those, 60226 images (72.7% of the dataset), spanning a total of 10632km2, were split as the training dataset. 10243 images,spanning 362km2, were chosen as the validation dataset and 10101 images were chosen for testing which cover a total land area of 288km2. The split of the dataset to training/validation/testing subsets is conducted by randomizing among tiles to aim for an approximate distribution of 70%/15%/15%. The training dataset consists of 4.5% positive and 95.5% negative pixels, the validation dataset consists of 3% positive and 97% negative pixels and the test dataset consists of 4.1% positive and 95.9% negative pixels. Authors selected a diverse set of patches to demonstrate road labels annotated on the original satellite images in Figure 2. As shown, the urban morphology, the illumination conditions, the road density, and the structure of the street networks are significantly diverse among the samples.
